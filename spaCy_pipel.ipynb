{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## spaCy’s Pipelines"
      ],
      "metadata": {
        "id": "Iq4Ky58-ke61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "haVybnltj7L7"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attribute Rulers¶\n",
        "\n",
        "- Dependency Parser\n",
        "- EntityLinker\n",
        "- EntityRecognizer\n",
        "- EntityRuler\n",
        "- Lemmatizer\n",
        "- Morpholog\n",
        "- SentenceRecognizer\n",
        "- Sentencizer\n",
        "- SpanCategorizer\n",
        "- Tagger\n",
        "- TextCategorizer\n",
        "- Tok2Vec\n",
        "- Tokenizer\n",
        "- TrainablePipe\n",
        "- Transformer\n",
        "\n",
        "### Matchers¶\n",
        "\n",
        "- DependencyMatcher\n",
        "- Matcher\n",
        "- PhraseMatcher\n"
      ],
      "metadata": {
        "id": "KO-NhZTZkqM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")"
      ],
      "metadata": {
        "id": "d9_vgrPcj_Iq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.add_pipe(\"sentencizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDit7wjvj_Uz",
        "outputId": "09ab875e-2dd4-4eda-d581-5f80ea4e276e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7f7a753f5900>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "s = requests.get(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\")\n",
        "soup = BeautifulSoup(s.content).text.replace(\"-\\n\", \"\").replace(\"\\n\", \" \")\n",
        "nlp.max_length = 5278439"
      ],
      "metadata": {
        "id": "ctDO51dlj_bc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "doc = nlp(soup)\n",
        "print (len(list(doc.sents)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-3PUbJfj_ge",
        "outputId": "3fc19c8a-b4e9-4455-e758-0e35fcedde4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94134\n",
            "CPU times: user 16.1 s, sys: 200 ms, total: 16.3 s\n",
            "Wall time: 16.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2 = spacy.load(\"en_core_web_sm\")\n",
        "nlp2.max_length = 5278439"
      ],
      "metadata": {
        "id": "VOxQRpWAj_lc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Der Zeitunterschied ist hier bemerkenswert. Unsere Textzeichenfolge umfasste rund 5,2 Millionen Zeichen. Das leere Modell mit nur dem Sentencizer erledigte seine Aufgabe in 7,54 Sekunden und fand rund 94.000 Sätze. Das kleine englische Modell, das effizienteste von spaCy, erledigte die gleiche Aufgabe in 46 Minuten und 15 Sekunden und fand rund 112.000 Sätze. Das kleine englische Modell brauchte also etwa 380-mal länger.\n",
        "\n",
        "Oft müssen Sätze schnell und nicht unbedingt genau gefunden werden. In diesen Fällen ist es sinnvoll, Tricks wie den oben genannten zu kennen. Dieses Notizbuch schließt den ersten Teil dieses Buches ab."
      ],
      "metadata": {
        "id": "FYS0YPNMlNLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2.analyze_pipes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXpDOKHmj_wg",
        "outputId": "bc97e923-0a6d-4a58-c757-e11182f1c2c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'tagger': {'assigns': ['token.tag'],\n",
              "   'requires': [],\n",
              "   'scores': ['tag_acc'],\n",
              "   'retokenizes': False},\n",
              "  'parser': {'assigns': ['token.dep',\n",
              "    'token.head',\n",
              "    'token.is_sent_start',\n",
              "    'doc.sents'],\n",
              "   'requires': [],\n",
              "   'scores': ['dep_uas',\n",
              "    'dep_las',\n",
              "    'dep_las_per_type',\n",
              "    'sents_p',\n",
              "    'sents_r',\n",
              "    'sents_f'],\n",
              "   'retokenizes': False},\n",
              "  'attribute_ruler': {'assigns': [],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'lemmatizer': {'assigns': ['token.lemma'],\n",
              "   'requires': [],\n",
              "   'scores': ['lemma_acc'],\n",
              "   'retokenizes': False},\n",
              "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False}},\n",
              " 'problems': {'tok2vec': [],\n",
              "  'tagger': [],\n",
              "  'parser': [],\n",
              "  'attribute_ruler': [],\n",
              "  'lemmatizer': [],\n",
              "  'ner': []},\n",
              " 'attrs': {'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
              "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
              "  'doc.ents': {'assigns': ['ner'], 'requires': []},\n",
              "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.ent_type': {'assigns': ['ner'], 'requires': []},\n",
              "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
              "  'token.ent_iob': {'assigns': ['ner'], 'requires': []}}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Beachten Sie die Wörterbuchstruktur. Dadurch erfahren wir nicht nur, was sich in der Pipeline befindet, sondern auch deren Reihenfolge. Jeder Schlüssel nach „summary“ ist eine Pipe. Der Wert ist ein Wörterbuch. Dieses Wörterbuch sagt uns ein paar verschiedene Dinge. Alle diese Wertewörterbücher geben Folgendes an: „assigns“, was einem Wert dessen entspricht, was diese bestimmte Pipe dem Token und dem Dokument zuweist, während es die Pipeline durchläuft. In einigen Fällen gibt es im Wörterbuch einen Schlüssel für „Scores“. Dies gibt an, wie das maschinelle Lernmodell bewertet wurde. Weitere Informationen zur Modellbewertung finden Sie weiter unten in unserem Abschnitt zum maschinellen Lernen."
      ],
      "metadata": {
        "id": "9ERRU4dTkdeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "Beachten Sie die Wörterbuchstruktur. Dadurch erfahren wir nicht nur, was sich in der Pipeline befindet, sondern auch deren Reihenfolge. Jeder Schlüssel nach „summary“ ist eine Pipe. Der Wert ist ein Wörterbuch. Dieses Wörterbuch sagt uns ein paar verschiedene Dinge. Alle diese Wertewörterbücher geben Folgendes an: „assigns“, was einem Wert dessen entspricht, was diese bestimmte Pipe dem Token und dem Dokument zuweist, während es die Pipeline durchläuft. In einigen Fällen gibt es im Wörterbuch einen Schlüssel für „Scores“. Dies gibt an, wie das maschinelle Lernmodell bewertet wurde. Weitere Informationen zur Modellbewertung finden Sie weiter unten in unserem Abschnitt zum maschinellen Lernen."
      ],
      "metadata": {
        "id": "478VMhC-lagz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTz6Mkb4j_3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gtSa8KLnj__U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}